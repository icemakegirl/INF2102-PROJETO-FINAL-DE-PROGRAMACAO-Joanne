# ðŸ§  LLM-DEIA Classifier --- ClassificaÃ§Ã£o de Postagens sobre Diversidade, Equidade, InclusÃ£o e Acessibilidade

Este repositÃ³rio contÃ©m um protÃ³tipo de classificador baseado em **Large
Language Models (LLMs)** capaz de analisar postagens de redes sociais e
determinar:

## ðŸ”¹ 1. DEIA Subtopic Classification

-   **race** (RaÃ§a)
-   **gender** (GÃªnero)
-   **inclusion** (InclusÃ£o)
-   **LGBTQIA+**
-   **none** (Nenhum)

## ðŸ”¹ 2. Post Stance Classification

-   **pro-DEIA** (PrÃ³-DEIA)
-   **anti-DEIA** (Anti-DEIA)
-   **neutral** (Neutro)

O objetivo do projeto Ã© avaliar se modelos de linguagem generalistas
conseguem reconhecer corretamente temas sensÃ­veis e suas nuances em
discursos sociais.

------------------------------------------------------------------------

## ðŸ“Š Dataset

O dataset utilizado foi coletado a partir de postagens do Reddit usando a seguinte query string:

```
"diversity" OR "lgbt" OR "inclusion" OR "DEI" OR "DEIA" OR "sexist" OR "sexism" OR "POC" OR "person of color"
```

O dataset estÃ¡ sendo rotulado manualmente para validar a classificaÃ§Ã£o automÃ¡tica realizada pelos LLMs.

------------------------------------------------------------------------

## ðŸ§± Arquitetura da SoluÃ§Ã£o

1.  Entrada: texto de redes sociais\
2.  Modelo carregado via HuggingFace (ex.: LLaMA 3 8B)\
3.  Prompt few-shot estruturado\
4.  ClassificaÃ§Ã£o dupla:
    -   Subtema\
    -   PosiÃ§Ã£o\
5.  SaÃ­da padronizada

------------------------------------------------------------------------

## â–¶ï¸ Como Executar

### 1. InstalaÃ§Ã£o

``` python
!pip install -U "transformers>=4.44.0" "huggingface_hub>=0.25.2"
```

### 2. AutenticaÃ§Ã£o

``` python
from huggingface_hub import login
login("SEU_TOKEN")
```

### 3. DefiniÃ§Ã£o do modelo

``` python
model_id = "meta-llama/Llama-3-8b"
```

### 4. Prompt Structure

**Subtopic Classification:**
```
You are an expert in classifying texts on diversity, equity, and inclusion using the following labels:

- gender: Statements related to women, men, non-binary people, gender equality, gender roles, or gender representation.
- race: Statements about ethnicity, racial minorities, discrimination based on race, or racial representation.
- LGBTQ+: Statements referring to sexual orientation, gender identity, same-sex relationships, or LGBTQ+ rights.
- inclusion: Statements about accessibility, disability inclusion, belonging, general DEIA practices, or inclusion that does not fit gender/race/LGBTQ+ specifically.
- none: Statements unrelated to DEIA or lacking any clear DEIA context.

Examples:
Input: "We need more women in leadership positions."
Output: gender

Input: "This policy supports minorities in the hiring process."
Output: race

Input: "The company is offering benefits for same-sex partners."
Output: LGBTQ+

Input: "We want a more inclusive workplace for everyone."
Output: inclusion

Input: "All employees must wear their ID badges."
Output: none

Classify the input using ONLY one of the following options: gender, race, LGBTQ+, inclusion, none.

Input: "{post}"
Output:
```

**Stance Classification:**
```
You are an expert in classifying texts on diversity, equity, and inclusion using the following labels:

- pro-DEIA: Supports, encourages, or speaks favorably about DEIA principles or actions.
- anti-DEIA: Opposes, criticizes, mocks, minimizes, or rejects DEIA principles.
- neutral: Unrelated, ambiguous, factual, or lacking any clear stance toward DEIA.
Examples:

Input: "We need more women and people of color in leadership roles."
Output: pro-DEIA

Input: "Hiring should be based on merit, not race or gender."
Output: anti-DEIA

Input: "Our company is hosting a webinar on leadership strategies."
Output: neutral

Input: "Quotas are a form of reverse discrimination."
Output: anti-DEIA

Input: "I don't see color, I treat everyone the same."
Output: anti-DEIA

Input: "Accessibility tools like screen readers help all users, not just those with disabilities."
Output: pro-DEIA

Input: "We should have more inclusive hiring practices."
Output: pro-DEIA


Input: "Hiring should be based on merit, not quotas."
Output: anti-DEIA

Classify the input using ONLY one of the following labels: pro-DEIA, anti-DEIA, neutral.

Input: "{post}"
Output:
```

------------------------------------------------------------------------

## ðŸ“š Resultados Esperados

-   Avaliar sensibilidade dos modelos a temas sociais\
-   Detectar vieses\
-   Comparar modelos e estratÃ©gias de prompting

------------------------------------------------------------------------

## ðŸ“¬ Contato

Projeto acadÃªmico desenvolvido para INF2102 -- PUC-Rio.
